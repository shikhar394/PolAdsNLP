{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} pip -m install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ve',\n",
      "  'said',\n",
      "  'it',\n",
      "  'befor',\n",
      "  'and',\n",
      "  'will',\n",
      "  'sai',\n",
      "  'it',\n",
      "  'again',\n",
      "  'the',\n",
      "  'mainstream',\n",
      "  'media',\n",
      "  'is',\n",
      "  'out',\n",
      "  'to',\n",
      "  'bring',\n",
      "  'down',\n",
      "  'my',\n",
      "  'administr',\n",
      "  'need',\n",
      "  'you',\n",
      "  'to',\n",
      "  'take',\n",
      "  'the',\n",
      "  'media',\n",
      "  'account',\n",
      "  'survei',\n",
      "  'to',\n",
      "  'do',\n",
      "  'your',\n",
      "  'part',\n",
      "  'to',\n",
      "  'fight',\n",
      "  'back',\n",
      "  'against',\n",
      "  'the',\n",
      "  'fake',\n",
      "  'new',\n",
      "  'attack',\n",
      "  'and',\n",
      "  'decept'],\n",
      " ['if',\n",
      "  'we',\n",
      "  'want',\n",
      "  'to',\n",
      "  'chang',\n",
      "  'congress',\n",
      "  'we',\n",
      "  'need',\n",
      "  'to',\n",
      "  'chang',\n",
      "  'who',\n",
      "  'we',\n",
      "  'send',\n",
      "  'to',\n",
      "  'congress'],\n",
      " ['happi',\n",
      "  'th',\n",
      "  'of',\n",
      "  'juli',\n",
      "  'let',\n",
      "  'celebr',\n",
      "  'our',\n",
      "  'freedom',\n",
      "  'and',\n",
      "  'independ',\n",
      "  'todai',\n",
      "  'and',\n",
      "  'cherish',\n",
      "  'them',\n",
      "  'alwai',\n",
      "  'freedom',\n",
      "  'is',\n",
      "  'never',\n",
      "  'more',\n",
      "  'than',\n",
      "  'on',\n",
      "  'gener',\n",
      "  'awai',\n",
      "  'from',\n",
      "  'extinct',\n",
      "  'we',\n",
      "  'didn',\n",
      "  'pass',\n",
      "  'it',\n",
      "  'to',\n",
      "  'our',\n",
      "  'children',\n",
      "  'in',\n",
      "  'the',\n",
      "  'bloodstream',\n",
      "  'it',\n",
      "  'must',\n",
      "  'be',\n",
      "  'fought',\n",
      "  'for',\n",
      "  'protect',\n",
      "  'and',\n",
      "  'hand',\n",
      "  'on',\n",
      "  'for',\n",
      "  'them',\n",
      "  'to',\n",
      "  'do',\n",
      "  'the',\n",
      "  'same',\n",
      "  'presid',\n",
      "  'reagan'],\n",
      " ['attent',\n",
      "  'nv',\n",
      "  'homeown',\n",
      "  'the',\n",
      "  'new',\n",
      "  'summer',\n",
      "  'electr',\n",
      "  'rate',\n",
      "  'have',\n",
      "  'start',\n",
      "  'thi',\n",
      "  'year',\n",
      "  'your',\n",
      "  'electr',\n",
      "  'bill',\n",
      "  'will',\n",
      "  'be',\n",
      "  'higher',\n",
      "  'than',\n",
      "  'last',\n",
      "  'year',\n",
      "  'the',\n",
      "  'good',\n",
      "  'new',\n",
      "  'is',\n",
      "  'that',\n",
      "  'nv',\n",
      "  'counti',\n",
      "  'solar',\n",
      "  'program',\n",
      "  'launch',\n",
      "  'no',\n",
      "  'cost',\n",
      "  'solar',\n",
      "  'program',\n",
      "  'year',\n",
      "  'ago',\n",
      "  'and',\n",
      "  'ha',\n",
      "  'help',\n",
      "  'of',\n",
      "  'homeown',\n",
      "  'go',\n",
      "  'solar',\n",
      "  'if',\n",
      "  'you',\n",
      "  'like',\n",
      "  'to',\n",
      "  'lower',\n",
      "  'your',\n",
      "  'electr',\n",
      "  'bill',\n",
      "  'and',\n",
      "  'enjoi',\n",
      "  'your',\n",
      "  'ac',\n",
      "  'again',\n",
      "  'without',\n",
      "  'fear',\n",
      "  'click',\n",
      "  'the',\n",
      "  'link',\n",
      "  'below',\n",
      "  'to',\n",
      "  'find',\n",
      "  'out',\n",
      "  'if',\n",
      "  'your',\n",
      "  'home',\n",
      "  'qualifi',\n",
      "  'http',\n",
      "  'com',\n",
      "  'no',\n",
      "  'cost',\n",
      "  'solar'],\n",
      " ['made', 'in', 'the', 'usa']]\n"
     ]
    }
   ],
   "source": [
    "TEXTFILE = \"AllText.json\"\n",
    "FileJson = json.load(open(TEXTFILE))\n",
    "RawSentences = {}\n",
    "PortStem = PorterStemmer()\n",
    "for i, sentenceid in enumerate(FileJson):\n",
    "    RawSentences[int(sentenceid)] = PortStem.stem_documents(gensim.utils.simple_preprocess(FileJson[sentenceid]))\n",
    "pprint(list(RawSentences.values())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140707070135296, 1468073206631424, 1973034292771842, 1826638557631491, 187993745381382]\n",
      "['work with presid trump on smart reform that reduc crime and cut cost', 'sign if you think sex ed should be sex posit', 'tommi gregori for state hous district', 'need help get on track for retir call me at to learn more about the option woodmenlif ha to help you', 'yike stori show trump is true pig']\n",
      "[2, 1, 0, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "Labels = {}\n",
    "LABELSFILE = \"Text.csv\"\n",
    "LabeledData = {} \n",
    "with open(LABELSFILE, 'r') as f:\n",
    "    File = csv.DictReader(f, delimiter=',')\n",
    "    for row in File:\n",
    "        ID = int(row['ID'])        \n",
    "        if row['ClearMajority'] != '-':\n",
    "            Labels[ID] = int(row['ClearMajority'])\n",
    "        elif row['SoftMajority'] != '-':\n",
    "            Labels[ID] = int(row['SoftMajority'])\n",
    "        elif row['damon'] != '-':\n",
    "            Labels[ID] = int(row['damon'])\n",
    "        LabeledData[ID] = RawSentences[ID]\n",
    "IDs = [ID for ID in Labels]\n",
    "print(IDs[:5])\n",
    "Corpus = [' '.join(LabeledData[ID]) for ID in IDs]\n",
    "print(Corpus[:5])\n",
    "Labels = [Labels[ID] for ID in IDs]\n",
    "print(Labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4667315233785822\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', \n",
    "                        encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "X_train = tfidf.fit_transform(Corpus)\n",
    "clf = MultinomialNB()\n",
    "\n",
    "SGD = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "\n",
    "scores = cross_val_score(SGD, X_train, Labels, cv = 10)\n",
    "print(sum(scores)/10)\n",
    "\n",
    "#SGD = GridSearchCV(svm.SVC(), tuned_parameters, cv=5,\n",
    "                       #scoring='%s_macro' % score)\n",
    "\n",
    "#SGD.fit(X_train, Labels)\n",
    "#     print(SGD.best_params_)\n",
    "#     means = SGD.cv_results_['mean_test_score']\n",
    "#     stds = SGD.cv_results_['std_test_score']\n",
    "\n",
    "#     print(means)\n",
    "    \n",
    "#     for mean, std, params in zip(means, stds, SGD.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#               % (mean, std * 2, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
